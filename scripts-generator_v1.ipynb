{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TV_Scripts_Generation_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_znO5juAfgcW",
        "colab_type": "code",
        "outputId": "f7ede901-1f51-4fab-d01f-de1669f43c69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHQ7PMzgfxoa",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkW0tRlVV54H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import helper\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peaEUSblbAsX",
        "colab_type": "code",
        "outputId": "51b27b0f-2b7c-44c3-96c5-2c331ce4e15d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "#Reading the Script\n",
        "with open(\"got1.txt\",'r') as file:\n",
        "  got1=file.read()\n",
        "with open(\"got2.txt\",'r') as file:\n",
        "  got2=file.read()\n",
        "with open(\"got3.txt\",'r') as file:\n",
        "  got3=file.read()\n",
        "with open(\"got1.txt\",'r') as file:\n",
        "  got4=file.read()\n",
        "with open(\"got1.txt\",'r') as file:\n",
        "  got5=file.read()\n",
        "\n",
        "text = got1+got2+got3+got4+got5\n",
        "print(len(text))\n",
        "print(len(got1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9702721\n",
            "1733704\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSRYdc0-bWdL",
        "colab_type": "code",
        "outputId": "ef72569f-4cbb-4e6e-c807-2fccddf560f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "source": [
        "view_sentence_range = (0, 10)\n",
        "\n",
        "print('Dataset Stats')\n",
        "print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n",
        "scenes = text.split('\\n\\n')\n",
        "print('Number of scenes: {}'.format(len(scenes)))\n",
        "sentence_count_scene = [scene.count('\\n') for scene in scenes]\n",
        "print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n",
        "\n",
        "sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n",
        "print('Number of lines: {}'.format(len(sentences)))\n",
        "word_count_sentence = [len(sentence.split()) for sentence in sentences]\n",
        "print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n",
        "\n",
        "print()\n",
        "print('The sentences {} to {}:'.format(*view_sentence_range))\n",
        "print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset Stats\n",
            "Roughly the number of unique words: 56308\n",
            "Number of scenes: 42815\n",
            "Average number of sentences in each scene: 0.0017984351278757444\n",
            "Number of lines: 42892\n",
            "Average number of words in each line: 41.90688240231279\n",
            "\n",
            "The sentences 0 to 10:\n",
            "\n",
            "The comet’s tail spread across the dawn, a red slash that bled above the crags of Dragonstone like a wound in the pink and purple sky.\n",
            "\n",
            "The maester stood on the windswept balcony outside his chambers. It was here the ravens came, after long flight. Their droppings speckled the gargoyles that rose twelve feet tall on either side of him, a hellhound and a wyvern, two of the thousand that brooded over the walls of the ancient fortress. When first he came to Dragonstone, the army of stone grotesques had made him uneasy, but as the years passed he had grown used to them. Now he thought of them as old friends. The three of them watched the sky together with foreboding.\n",
            "\n",
            "The maester did not believe in omens. And yet . . . old as he was, Cressen had never seen a comet half so bright, nor yet that color, that terrible color, the color of blood and flame and sunsets. He wondered if his gargoyles had ever seen its like. They had been here so much longer than he had, and would still be here long after he was gone. If stone tongues could speak . . .\n",
            "\n",
            "Such folly. He leaned against the battlement, the sea crashing beneath him, the black stone rough beneath his fingers. Talking gargoyles and prophecies in the sky. I am an old done man, grown giddy as a child again. Had a lifetime’s hard-won wisdom fled him along with his health and strength? He was a maester, trained and chained in the great Citadel of Oldtown. What had he come to, when superstition filled his head as if he were an ignorant fieldhand?\n",
            "\n",
            "And yet . . . and yet . . . the comet burned even by day now, while pale grey steam rose from the hot vents of Dragonmont behind the castle, and yestermorn a white raven had brought word from the Citadel itself, word long-expected but no less fearful for all that, word of summer’s end. Omens, all. Too many to deny. What does it all mean? he wanted to cry.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8-MAMnodbCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_lookup_tables(text):\n",
        "      #text is split into words\n",
        "      words = sorted(list(set(text)))\n",
        "      vocab_to_int = {word:index for index,word in enumerate(words)}\n",
        "      int_to_vocab = {index:word for index,word in enumerate(words)}\n",
        "      return vocab_to_int,int_to_vocab\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRX_Qe6ZfERJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def token_lookup():\n",
        "    mark_to_token={}\n",
        "    mark_to_token['.'] = \"||Period||\"\n",
        "    mark_to_token[','] = \"||Comma||\"\n",
        "    mark_to_token['\"'] = \"||QuotationMark||\"\n",
        "    mark_to_token[';'] = \"||Semicolon||\"\n",
        "    mark_to_token['!'] = \"||Exclamationmark||\"\n",
        "    mark_to_token['?'] = \"||Questionmark||\"\n",
        "    mark_to_token['('] = \"||LeftParentheses||\"\n",
        "    mark_to_token[')'] = \"||RightParentheses||\"\n",
        "    mark_to_token['--'] = \"||Dash||\"\n",
        "    mark_to_token['\\n'] = \"||Return||\"\n",
        "    return mark_to_token\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuSM05AQiVVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n",
        "    import pickle\n",
        "    \"\"\"\n",
        "    Preprocess Text Data\n",
        "    \"\"\"\n",
        "    with open(\"got1.txt\",'r') as file:\n",
        "      got1=file.read()\n",
        "    with open(\"got2.txt\",'r') as file:\n",
        "      got2=file.read()\n",
        "    with open(\"got3.txt\",'r') as file:\n",
        "      got3=file.read()\n",
        "    with open(\"got1.txt\",'r') as file:\n",
        "      got4=file.read()\n",
        "    with open(\"got1.txt\",'r') as file:\n",
        "      got5=file.read()\n",
        "\n",
        "    text = got1+got2+got3+got4+got5\n",
        "    \n",
        "\n",
        "    token_dict = token_lookup()\n",
        "    for key, token in token_dict.items():\n",
        "        text = text.replace(key, ' {} '.format(token))\n",
        "\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "\n",
        "    vocab_to_int, int_to_vocab = create_lookup_tables(text)\n",
        "    int_text = [vocab_to_int[word] for word in text]\n",
        "    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('preprocess.p', 'wb'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "she8ZHoupMv8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preprocess_and_save_data(\"none\",token_lookup,create_lookup_tables)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QFq1q08Zod-",
        "colab_type": "code",
        "outputId": "3e75d5d9-6c40-4992-c351-266825ab865e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text[:100]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nThe comet’s tail spread across the dawn, a red slash that bled above the crags of Dragonstone like '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmGlFQfjp3oE",
        "colab_type": "text"
      },
      "source": [
        "**Now our checkpoint has been created**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eubaXNs5qyab",
        "colab_type": "text"
      },
      "source": [
        "# Building The Netwok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpy6oE3Qp2nc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "int_text, vocab_to_int, int_to_vocab, token_dict = pickle.load(open('preprocess.p', mode='rb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNCNqBD1q7fF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TibNH41orD4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_inputs():\n",
        "  Inputs = tf.placeholder(tf.int32,[None,None],name='input')\n",
        "  Targets = tf.placeholder(tf.int32,[None,None],name='Targets')\n",
        "  LearningRate= tf.placeholder(tf.float32,name='learningrate')\n",
        "  return Inputs,Targets,LearningRate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgF-eAyIxlw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_init_cell(batch_size,rnn_size):\n",
        "  def getCell(rnn_siz):\n",
        "    rnn_cell = tf.contrib.rnn.BasicLSTMCell(rnn_siz)\n",
        "    drop = tf.contrib.rnn.DropoutWrapper(rnn_cell,output_keep_prob=0.90)\n",
        "    return drop\n",
        "\n",
        "  cell = tf.contrib.rnn.MultiRNNCell([getCell(rnn_size[i]) for i in range(2)])\n",
        "  initial_state = cell.zero_state(batch_size,tf.float32)\n",
        "  initial_state =  tf.identity(initial_state,\"initial_state\")\n",
        "  return cell,initial_state\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fuqj6VQh4H4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embed(input_data,vocab_size,embed_dim):\n",
        "  embeddings = tf.Variable(tf.truncated_normal([vocab_size,embed_dim]))\n",
        "  embed = tf.nn.embedding_lookup(embeddings,input_data)\n",
        "  return embed\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_RyO2LdBQ3h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_rnn(cell,inputs):\n",
        "  outputs,final_state  = tf.nn.dynamic_rnn(cell,inputs,dtype=tf.float32)\n",
        "  final_state = tf.identity(final_state,name='final_state')\n",
        "\n",
        "  return (outputs,final_state)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cyw6JUvDxvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_nn(cell,rnn_size,input_data,vocab_size,embed_dim):\n",
        "  embed = get_embed(input_data,vocab_size,embed_dim)\n",
        "  (outputs,final_state)  = build_rnn(cell,embed)\n",
        "\n",
        "  Logits = tf.contrib.layers.fully_connected(outputs,vocab_size,activation_fn=tf.keras.activations.linear)\n",
        "\n",
        "  return (Logits,final_state)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pbc_ZdJhGOyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_batches(int_text,batch_size,seq_len):\n",
        "  chars_per_batch = batch_size*seq_len\n",
        "  num_batches = len(int_text)//chars_per_batch\n",
        "  int_text = int_text[:num_batches*chars_per_batch]\n",
        "  batches = np.zeros([num_batches,2,batch_size,seq_len])\n",
        "  counter = 0\n",
        "  for i in range(batch_size):\n",
        "      for j in range(0,num_batches):\n",
        "            batches[j,0,i,:] = int_text[counter:counter+seq_len]\n",
        "            y_temp = int_text[counter+1:counter+seq_len+1]\n",
        "            batches[j,1,i,:len(y_temp)] = y_temp            \n",
        "            counter+=seq_len\n",
        "  batches[num_batches-1,1,-1,-1] = int_text[0]\n",
        "  return batches            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQjfrayNhZfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Hyperparameters\n",
        "\n",
        "num_epochs = 200\n",
        "batch_size=  256\n",
        "rnn_size = [300,300]\n",
        "embed_dims = 350\n",
        "seq_len = 42\n",
        "learning_rate = 0.001\n",
        "show_every_n_batches = 50\n",
        "\n",
        "save_dir = './save'\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEs5Qst5mcQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Building the Graph\n",
        "from tensorflow.contrib import seq2seq\n",
        "\n",
        "train_graph = tf.Graph()\n",
        "with train_graph.as_default():\n",
        "  vocab_size = len(int_to_vocab)\n",
        "  input_text,targets,lr = get_inputs()\n",
        "  input_data_shape = tf.shape(input_text)\n",
        "  cell,initial_state = get_init_cell(input_data_shape[0],rnn_size)\n",
        "  Logits,Final_state =   build_nn(cell,rnn_size,input_text,vocab_size,embed_dims)\n",
        "\n",
        "  probs = tf.nn.softmax(Logits,name='probs')\n",
        "  #Loss Function\n",
        "  cost = seq2seq.sequence_loss(Logits,targets,\n",
        "                               tf.ones([input_data_shape[0],input_data_shape[1]]))\n",
        "  \n",
        "  #optimizer\n",
        "  optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "  gradients=optimizer.compute_gradients(cost)\n",
        "\n",
        "  clipped_gradients = [(tf.clip_by_value(grad,-1.,1.),var) for grad,var in gradients if grad is not None]\n",
        "\n",
        "  train_op = optimizer.apply_gradients(clipped_gradients)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_heeS7Tlqim3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training the Network\n",
        "batches = get_batches(int_text,batch_size,seq_len)\n",
        "\n",
        "with tf.Session(graph=train_graph) as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "\n",
        "  for epoch_i in range(num_epochs):\n",
        "      state = sess.run(initial_state,{input_text: batches[0][0]})\n",
        "      for batch_i,(x,y) in enumerate(batches):\n",
        "           feed = {input_text:x,\n",
        "                  targets:y,\n",
        "                  lr:learning_rate,\n",
        "                  initial_state:state}\n",
        "\n",
        "           train_loss,state,_ = sess.run([cost,Final_state,train_op],feed_dict=feed)\n",
        "           if (epoch_i * len(batches) + batch_i) % show_every_n_batches == 0:\n",
        "                print('Epoch {:>3} Batch {:>4}/{}   train_loss = {:.3f}'.format(\n",
        "                    epoch_i,\n",
        "                    batch_i,\n",
        "                    len(batches),\n",
        "                    train_loss))\n",
        "      if(epoch_i%5==0):\n",
        "            # Save Model\n",
        "            saver = tf.train.Saver()\n",
        "            saver.save(sess, save_dir)\n",
        "            print('Model Trained and Saved')\n",
        "\n",
        "  # Save Model\n",
        "  saver = tf.train.Saver()\n",
        "  saver.save(sess, save_dir)\n",
        "  print('Model Trained and Saved')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo5ZJiHPPH9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump((seq_len,save_dir), open('params.p', 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFcrEpnx3tyr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_tensors(loaded_graph):\n",
        "  with tf.Session(graph=loaded_graph):\n",
        "      return (tf.get_default_graph().get_tensor_by_name('input:0')\n",
        "      ,tf.get_default_graph().get_tensor_by_name(\"initial_state:0\")\n",
        "      ,tf.get_default_graph().get_tensor_by_name('final_state:0')\n",
        "      ,tf.get_default_graph().get_tensor_by_name('probs:0') )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSOCshAlB6_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pick_word(probabilities,int_to_vocab,top_n=5):\n",
        "      p  = np.squeeze(probabilities)\n",
        "      vocab_size = len(int_to_vocab)\n",
        "      p[np.argsort(p)[:-top_n]] = 0\n",
        "      p = p / np.sum(p)\n",
        "      c = np.random.choice(vocab_size, 1, p=p)[0]\n",
        "      return int_to_vocab[c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1SuxflTHDXr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "a5c66fce-8dfa-4d81-ffed-ec99b2e8979c"
      },
      "source": [
        "seq_length = 42\n",
        "\n",
        "prime_word = 'jon'\n",
        "\n",
        "loaded_graph = tf.Graph()\n",
        "with tf.Session(graph=loaded_graph) as sess:\n",
        "  loader = tf.train.import_meta_graph('save' + '.meta')\n",
        "  loader.restore(sess, save_dir)\n",
        "\n",
        "  input_text, initial_state, final_state, probs = get_tensors(loaded_graph)\n",
        "\n",
        "  gen_sentences = [prime_word]\n",
        "  prev_state = sess.run(initial_state,{input_text:np.array([[1]])})\n",
        "\n",
        "  for n in range(gen_length):\n",
        "    #Dynamic Input\n",
        "        dyn_input = [ [vocab_to_int[word] for word in gen_sentences[-seq_length:]] ]\n",
        "        dyn_seq_length = len(dyn_input[0])\n",
        "        probabilities, prev_state = sess.run(\n",
        "                [probs, final_state],\n",
        "                {input_text: dyn_input, initial_state: prev_state})\n",
        "        pred_word = pick_word(probabilities[0][dyn_seq_length-1], int_to_vocab)\n",
        "        gen_sentences.append(pred_word)\n",
        "  \n",
        "  tv_script = ' '.join(gen_sentences)\n",
        "  for key, token in token_dict.items():\n",
        "        ending = ' ' if key in ['\\n', '(', '\"'] else ''\n",
        "        tv_script = tv_script.replace(' ' + token.lower(), key)\n",
        "  tv_script = tv_script.replace('\\n ', '\\n')\n",
        "  tv_script = tv_script.replace('( ', '(')\n",
        "        \n",
        "  print(tv_script)\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./save\n",
            "jon arryn resumed us. ”\n",
            "\n",
            "a different sort of pain they made a rude noise. the girl was a timid older than her, arya thought. joffrey made a jest, to keep her in the mountains. i cannot fault them to her. she could feel the blood of the poor sword of yours. but it was the same stories long ago, with the way his head seemed to require a certain show of his... and the puissant death. ”\n",
            "\n",
            "“i know the same. ” the ruby on the throat was hot to make a certain sort of natural that look like this. she glanced up in the saddle. “i am not so scared. you are the blood of your youth, my lady. ”\n",
            "\n",
            "the boy, he thought. the words was growing harder to her, and tyrion saw her, with all the chivalry of its end. in a growing distance, a lordling bellows and a direwolf in silence.\n",
            "\n",
            "the first line passed to lay a long summer mile,\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vWIMLPp4KbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}